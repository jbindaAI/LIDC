{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d295fab-54ec-4366-b50e-769e7727b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from E2E_vanilla import Vanilla_E2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e01408-8ab4-4813-a255-89fff84a8004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jbinda/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "model = Vanilla_E2E()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81e678cc-381e-49e2-be13-a6e1511bfdff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('qkv',\n",
       "               Linear(in_features=384, out_features=1152, bias=True)),\n",
       "              ('attn_drop', Dropout(p=0.0, inplace=False)),\n",
       "              ('proj', Linear(in_features=384, out_features=384, bias=True)),\n",
       "              ('proj_drop', Dropout(p=0.0, inplace=False))]),\n",
       " 'num_heads': 6,\n",
       " 'scale': 0.125}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(model.dino.blocks[0].attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "effa0224-0cca-484c-b966-dec1ea7af0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla_E2E(\n",
      "  (dino): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(8, 8), stride=(8, 8))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (linear): Linear(in_features=384, out_features=1, bias=True)\n",
      "  (accuracy): BinaryAccuracy()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4fa25-b3ad-4a7b-8977-2de40c44d160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dc8dfc-a9ee-40a2-965d-0d13372dff40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeaa640-1ea8-42e5-8b22-3d6bef6358d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92994ef-e6ce-4e49-8a29-bf0481fbd20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from functools import partial\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.layers import DropPath, to_2tuple, to_3tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f30fb9-b7df-4d98-be6f-db45f0a21fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dino3d import VisionTransformer3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabefc61-bf32-4f57-b6ca-87ebb40abe62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: torch.Size([384, 3, 8, 8]) tensor(-1.8925)\n",
      "Centering!!!\n",
      "New: torch.Size([384, 1, 8, 8, 5]) tensor(-1.8925)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VisionTransformer3D:\n\tsize mismatch for cls_token: copying a param with shape torch.Size([1, 1, 384]) from checkpoint, the shape in current model is torch.Size([1, 1, 768]).\n\tsize mismatch for pos_embed: copying a param with shape torch.Size([1, 1025, 384]) from checkpoint, the shape in current model is torch.Size([1, 1025, 768]).\n\tsize mismatch for patch_embed.proj.weight: copying a param with shape torch.Size([384, 1, 8, 8, 5]) from checkpoint, the shape in current model is torch.Size([768, 1, 16, 16, 5]).\n\tsize mismatch for patch_embed.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.0.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.0.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.1.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.1.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.2.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.2.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.3.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.3.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.4.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.4.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.5.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.5.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.6.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.6.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.6.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.6.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.6.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.6.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.7.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.7.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.7.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.7.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.7.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.7.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.8.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.8.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.8.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.8.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.8.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.8.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.9.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.9.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.9.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.9.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.9.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.9.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.10.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.10.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.10.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.10.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.10.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.10.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.11.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.11.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.11.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.11.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.11.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.11.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m      4\u001b[0m bootstrap_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentering\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m encoder \u001b[38;5;241m=\u001b[39m VisionTransformer3D(\n\u001b[1;32m      6\u001b[0m     img_size\u001b[38;5;241m=\u001b[39mimg_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_2d \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, img_size[\u001b[38;5;241m1\u001b[39m], img_size[\u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m      7\u001b[0m     patch_size\u001b[38;5;241m=\u001b[39m(patch_size, patch_size, img_size[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     norm_layer\u001b[38;5;241m=\u001b[39mpartial(nn\u001b[38;5;241m.\u001b[39mLayerNorm, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m encoder\u001b[38;5;241m.\u001b[39minit_weights(bootstrap_method\u001b[38;5;241m=\u001b[39mbootstrap_method)\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     20\u001b[0m out \u001b[38;5;241m=\u001b[39m encoder(x)\n",
      "File \u001b[0;32m~/INFORM/LIDC/3DViT/3DViT/dino3d.py:399\u001b[0m, in \u001b[0;36mVisionTransformer3D.init_weights\u001b[0;34m(self, pretrained, bootstrap_method)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pretrained, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(_init_weights)\n\u001b[0;32m--> 399\u001b[0m     load_checkpoint(\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    401\u001b[0m         pretrained_weights\u001b[38;5;241m=\u001b[39mpretrained,\n\u001b[1;32m    402\u001b[0m         bootstrap_method\u001b[38;5;241m=\u001b[39mbootstrap_method,\n\u001b[1;32m    403\u001b[0m         checkpoint_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pretrained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(_init_weights)\n",
      "File \u001b[0;32m~/INFORM/LIDC/3DViT/3DViT/dino3d.py:94\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(model, pretrained_weights, checkpoint_key, map_location, bootstrap_method)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# remove `backbone.` prefix induced by multicrop wrapper\u001b[39;00m\n\u001b[1;32m     93\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m): v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 94\u001b[0m msg \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrained weights found at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and loaded with msg: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m         pretrained_weights, msg\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VisionTransformer3D:\n\tsize mismatch for cls_token: copying a param with shape torch.Size([1, 1, 384]) from checkpoint, the shape in current model is torch.Size([1, 1, 768]).\n\tsize mismatch for pos_embed: copying a param with shape torch.Size([1, 1025, 384]) from checkpoint, the shape in current model is torch.Size([1, 1025, 768]).\n\tsize mismatch for patch_embed.proj.weight: copying a param with shape torch.Size([384, 1, 8, 8, 5]) from checkpoint, the shape in current model is torch.Size([768, 1, 16, 16, 5]).\n\tsize mismatch for patch_embed.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.0.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.0.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.0.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.0.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.0.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.0.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.0.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.1.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.1.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.1.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.1.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.1.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.1.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.1.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.2.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.2.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.2.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.2.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.2.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.2.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.2.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.3.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.3.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.3.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.3.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.3.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.3.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.3.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.4.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.4.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.4.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.4.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.4.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.4.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.4.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.5.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.5.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.5.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.5.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.5.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.5.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.6.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.6.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.6.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.6.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.6.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.6.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.6.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.7.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.7.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.7.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.7.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.7.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.7.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.7.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.8.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.8.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.8.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.8.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.8.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.8.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.8.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.9.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.9.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.9.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.9.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.9.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.9.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.9.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.10.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.10.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.10.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.10.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.10.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.10.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.10.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm1.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm1.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.attn.qkv.weight: copying a param with shape torch.Size([1152, 384]) from checkpoint, the shape in current model is torch.Size([2304, 768]).\n\tsize mismatch for blocks.11.attn.qkv.bias: copying a param with shape torch.Size([1152]) from checkpoint, the shape in current model is torch.Size([2304]).\n\tsize mismatch for blocks.11.attn.proj.weight: copying a param with shape torch.Size([384, 384]) from checkpoint, the shape in current model is torch.Size([768, 768]).\n\tsize mismatch for blocks.11.attn.proj.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm2.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.norm2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for blocks.11.mlp.fc1.weight: copying a param with shape torch.Size([1536, 384]) from checkpoint, the shape in current model is torch.Size([3072, 768]).\n\tsize mismatch for blocks.11.mlp.fc1.bias: copying a param with shape torch.Size([1536]) from checkpoint, the shape in current model is torch.Size([3072]).\n\tsize mismatch for blocks.11.mlp.fc2.weight: copying a param with shape torch.Size([384, 1536]) from checkpoint, the shape in current model is torch.Size([768, 3072]).\n\tsize mismatch for blocks.11.mlp.fc2.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for norm.weight: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768]).\n\tsize mismatch for norm.bias: copying a param with shape torch.Size([384]) from checkpoint, the shape in current model is torch.Size([768])."
     ]
    }
   ],
   "source": [
    "force_2d = False\n",
    "img_size = (5, 512, 512)\n",
    "patch_size = 16\n",
    "bootstrap_method = \"centering\"\n",
    "encoder = VisionTransformer3D(\n",
    "    img_size=img_size if not force_2d else (1, img_size[1], img_size[2]),\n",
    "    patch_size=(patch_size, patch_size, img_size[0])\n",
    "    if not force_2d\n",
    "    else (patch_size, patch_size, 1),\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    in_chans=1,\n",
    "    num_heads=12,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    ")\n",
    "encoder.init_weights(bootstrap_method=bootstrap_method)\n",
    "x = torch.randn(4, 1, 5, 512, 512)\n",
    "out = encoder(x)\n",
    "print([y.shape for y in out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb5dc9a5-21ad-4cb8-8d27-2a23c90161aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer3D(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv3d(1, 768, kernel_size=(16, 16, 5), stride=(16, 16, 5))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4fb6f1-9ecd-4024-8321-9dfc7d4d88ab",
   "metadata": {},
   "source": [
    "## Docelowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "734038df-da94-497c-a263-26a0483a5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (7, 224, 224)\n",
    "patch_size = 8\n",
    "bootstrap_method = \"centering\"\n",
    "encoder = VisionTransformer3D(\n",
    "    img_size=img_size,\n",
    "    patch_size=(patch_size, patch_size, img_size[0]),\n",
    "    embed_dim=384,\n",
    "    depth=12,\n",
    "    in_chans=1,\n",
    "    num_heads=6,\n",
    "    mlp_ratio=4,\n",
    "    qkv_bias=True,\n",
    "    norm_layer=partial(nn.LayerNorm, eps=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af82366-1f80-4420-8c69-31eac061a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old: torch.Size([384, 3, 8, 8]) tensor(-1.8925)\n",
      "Centering!!!\n",
      "New: torch.Size([384, 1, 8, 8, 7]) tensor(-1.8925)\n",
      "Pretrained weights found at ./pretrained_models/dino_deitsmall8_pretrain.pth and loaded with msg: <All keys matched successfully>\n",
      "[torch.Size([384]), torch.Size([384]), torch.Size([384]), torch.Size([384])]\n"
     ]
    }
   ],
   "source": [
    "encoder.init_weights(bootstrap_method=bootstrap_method)\n",
    "x = torch.randn(4, 1, 7, 224, 224)\n",
    "out = encoder(x)\n",
    "print([y.shape for y in out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10596386-d080-44ef-b292-2a3e689c5abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer3D(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv3d(1, 384, kernel_size=(8, 8, 7), stride=(8, 8, 7))\n",
      "  )\n",
      "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x Block(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): Attention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (drop_path): Identity()\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (mlp): Mlp(\n",
      "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (act): GELU(approximate='none')\n",
      "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Identity()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595da1f2-5468-4ff5-bf43-14a5013b0949",
   "metadata": {},
   "source": [
    "### Closer look on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed73a4c9-3f39-4047-8c55-9b9acd069f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca60769a-08a8-4b4a-8f56-4fd3b77539de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Trainable\n",
       "============================================================================================================================================\n",
       "VisionTransformer3D                      [32, 1, 7, 224, 224]      [32, 384]                 301,824                   True\n",
       "├─PatchEmbed: 1-1                        [32, 1, 7, 224, 224]      [32, 784, 384]            --                        True\n",
       "│    └─Conv3d: 2-1                       [32, 1, 224, 224, 7]      [32, 384, 28, 28, 1]      172,416                   True\n",
       "├─Dropout: 1-2                           [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "├─ModuleList: 1-3                        --                        --                        --                        True\n",
       "│    └─Block: 2-2                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-1               [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-2               [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-3                [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-4               [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-5                     [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-6                [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-3                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-7               [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-8               [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-9                [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-10              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-11                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-12               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-4                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-13              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-14              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-15               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-16              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-17                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-18               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-5                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-19              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-20              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-21               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-22              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-23                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-24               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-6                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-25              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-26              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-27               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-28              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-29                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-30               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-7                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-31              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-32              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-33               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-34              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-35                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-36               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-8                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-37              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-38              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-39               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-40              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-41                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-42               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-9                        [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-43              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-44              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-45               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-46              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-47                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-48               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-10                       [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-49              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-50              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-51               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-52              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-53                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-54               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-11                       [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-55              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-56              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-57               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-58              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-59                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-60               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-12                       [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-61              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-62              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-63               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-64              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-65                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-66               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    └─Block: 2-13                       [32, 785, 384]            [32, 785, 384]            --                        True\n",
       "│    │    └─LayerNorm: 3-67              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Attention: 3-68              [32, 785, 384]            [32, 785, 384]            591,360                   True\n",
       "│    │    └─Identity: 3-69               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "│    │    └─LayerNorm: 3-70              [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "│    │    └─Mlp: 3-71                    [32, 785, 384]            [32, 785, 384]            1,181,568                 True\n",
       "│    │    └─Identity: 3-72               [32, 785, 384]            [32, 785, 384]            --                        --\n",
       "├─LayerNorm: 1-4                         [32, 785, 384]            [32, 785, 384]            768                       True\n",
       "============================================================================================================================================\n",
       "Total params: 21,768,576\n",
       "Trainable params: 21,768,576\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.01\n",
       "============================================================================================================================================\n",
       "Input size (MB): 44.96\n",
       "Forward/backward pass size (MB): 10340.50\n",
       "Params size (MB): 85.87\n",
       "Estimated Total Size (MB): 10471.32\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "summary(encoder, input_size=(batch_size, 1, 7, 224, 224),\n",
    "        col_names=[\"input_size\",\n",
    "                \"output_size\",\n",
    "                \"num_params\",\n",
    "                \"trainable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30b651-c2dc-40b2-a823-39b377fd1ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11d92d-5583-4cde-9a47-51a1365ff069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf604472-b59f-49c7-8d6a-9b13b233d44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489cc013-9b1d-44de-8288-d73175fd6515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09136d42-51a9-489d-a34b-47e8fb6ce81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45bd3eeb-73fd-47e4-8fe6-e8a93b18ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from E2E_3DViT_dataset import E2E_3D_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c8d42c7d-f7ca-4ec4-a4a4-198ddb74e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = E2E_3D_Dataset(mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a610f0d-3a12-4366-948a-8f1c09262ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torch.utils.data.DataLoader(train_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cd99db6f-5914-46b1-afdc-25aa801d5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = iter(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bced27d9-cd98-4bf7-8387-5cfcc2c7640d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b =next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "31619814-51ac-440e-94f5-40642a62b53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 7, 32, 32])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e48da-0ea3-42ca-b51e-e589b89375c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
